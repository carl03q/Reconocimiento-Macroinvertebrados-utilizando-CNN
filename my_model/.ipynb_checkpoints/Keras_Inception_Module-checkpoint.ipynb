{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#import tensorflow.contrib.slim as slim\n",
    "#eval = slim.evaluation.evaluate_once\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size = 32\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(299, 299),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(299, 299),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "input_img = Input(shape = (299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, concatenate\n",
    "\n",
    "conv1_3_3 = Conv2D(32, (3,3), strides=(2,2), activation='relu')(input_img)\n",
    "conv2_3_3 = Conv2D(32, (3,3), activation='relu')(conv1_3_3)\n",
    "conv3_3_3 = Conv2D(64, (3,3), padding='same', activation='relu')(conv2_3_3)\n",
    "pool1_3_3 = MaxPooling2D((3,3), strides=(2,2))(conv3_3_3)\n",
    "conv3_3_3_reduce = Conv2D(80, (1,1), activation='relu')(pool1_3_3)\n",
    "conv3_3_3 = Conv2D(192, (3,3), activation='relu')(conv3_3_3_reduce)\n",
    "pool2_3_3 = MaxPooling2D((3,3), strides=(2,2))(conv3_3_3)\n",
    "\n",
    "tower_1 = Conv2D(64, (1,1), padding='same', activation='relu')(pool2_3_3)\n",
    "tower_1 = Conv2D(64, (3,3), padding='same', activation='relu')(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64, (1,1), padding='same', activation='relu')(pool2_3_3)\n",
    "tower_2 = Conv2D(64, (5,5), padding='same', activation='relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(pool2_3_3)\n",
    "tower_3 = Conv2D(64, (1,1), padding='same', activation='relu')(tower_3)\n",
    "\n",
    "output = concatenate([tower_1, tower_2, tower_3], axis = 3)\n",
    "\n",
    "#output = pool2_3_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "#pool3_5_5 = MaxPooling2D((5,5), strides=(3,3))(output)\n",
    "#conv4_reduce = Conv2D(128, (1,1), activation='relu')(pool3_5_5)\n",
    "#conv4_3_3 = Conv2D(768, (3,3), activation='relu')(conv4_reduce)\n",
    "#output = pool3_5_5\n",
    "output = Flatten()(output)\n",
    "out    = Dense(2, activation='softmax')(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 299, 299, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)               (None, 149, 149, 32)  896         input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)               (None, 147, 147, 32)  9248        conv2d_69[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)               (None, 147, 147, 64)  18496       conv2d_70[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D)  (None, 73, 73, 64)    0           conv2d_71[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)               (None, 73, 73, 80)    5200        max_pooling2d_29[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)               (None, 71, 71, 192)   138432      conv2d_72[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling2D)  (None, 35, 35, 192)   0           conv2d_73[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)               (None, 35, 35, 64)    12352       max_pooling2d_30[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, 35, 35, 64)    12352       max_pooling2d_30[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D)  (None, 35, 35, 192)   0           max_pooling2d_30[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)               (None, 35, 35, 64)    36928       conv2d_74[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)               (None, 35, 35, 64)    102464      conv2d_76[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)               (None, 35, 35, 64)    12352       max_pooling2d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 35, 35, 192)   0           conv2d_75[0][0]                  \n",
      "                                                                   conv2d_77[0][0]                  \n",
      "                                                                   conv2d_78[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 235200)        0           concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 2)             470402      flatten_11[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 819,122\n",
      "Trainable params: 819,122\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "model = Model(inputs = input_img, outputs = out)\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate,\n",
    "          momentum=0.9,\n",
    "          decay=decay,\n",
    "          nesterov=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=epochs,\n",
    "          batch_size=32)\n",
    "'''\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=25,\n",
    "        validation_data=validation_generator,\n",
    "        #validation_steps=40 // batch_size)\n",
    "        validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(os.path.join(os.getcwd(), 'model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "#print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "scores = model.evaluate_generator(validation_generator, 140)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
